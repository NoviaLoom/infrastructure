# Core Service - Infrastructure LLM

Service d'infrastructure pour la g√©n√©ration de texte utilisant des mod√®les de langage (LLM) avec support Google Search et Google Maps grounding.

## üìã Description

Le Core Service fournit une interface unifi√©e pour l'utilisation de diff√©rents providers LLM :
- **Google Gemini** (mod√®les 2.5) avec Google Search et Google Maps grounding
- **OpenAI** (GPT-4, GPT-3.5-turbo)
- **Module Shared** : Utilise le package partag√© pour CORS, Health checks, Logging, Auth service-to-service

## üèóÔ∏è Architecture Interne

```mermaid
graph TD
    ROOT[core-service/]
    
    ROOT --> API[api/<br/>Endpoints FastAPI]
    ROOT --> CORE[core/llm/<br/>Logique LLM]
    ROOT --> MAIN[main.py<br/>Point d'entr√©e]
    
    API --> LLM_ROUTER[llm_router.py<br/>Routes LLM]
    API --> HEALTH_ROUTER[health_router.py<br/>Health checks]
    
    CORE --> FACTORY[llm_factory.py<br/>Factory pattern]
    CORE --> SERVICE[llm_service.py<br/>Service principal]
    CORE --> REQUEST[llm_request.py<br/>Mod√®les de requ√™te]
    CORE --> RESPONSE[llm_response.py<br/>Mod√®les de r√©ponse]
    CORE --> PROVIDERS[providers/<br/>Providers LLM]
    
    PROVIDERS --> GOOGLE[google_provider.py<br/>Google Gemini]
    PROVIDERS --> OPENAI[openai_provider.py<br/>OpenAI]
    PROVIDERS --> BASE[llm_provider_base.py<br/>Interface commune]
```

## üöÄ API Endpoints

### G√©n√©ration de Texte

#### POST `/llm/generate`

G√©n√®re du texte en utilisant un provider LLM sp√©cifi√©.

**Param√®tres :**
```json
{
  "prompt": "Votre prompt ici",
  "provider": "google",           // "google" ou "openai"
  "model": "gemini-2.5-flash-lite", // Mod√®le sp√©cifique
  "temperature": 0.7,             // Cr√©ativit√© (0.0-1.0)
  "max_tokens": 1000,             // Limite de tokens
  "system_message": "Contexte",   // Message syst√®me
  "use_search": true,             // Google Search grounding (Gemini uniquement)
  "use_maps": false,              // Google Maps grounding (Gemini uniquement)
  "stream": false                 // Streaming (non support√© actuellement)
}
```

**R√©ponse :**
```json
{
  "text": "R√©ponse g√©n√©r√©e par l'IA",
  "provider": "google",
  "model": "gemini-2.5-flash-lite",
  "usage": {
    "prompt_tokens": 50,
    "completion_tokens": 200,
    "total_tokens": 250
  },
  "finish_reason": "stop",
  "metadata": {
    "search_enabled": true,
    "maps_enabled": false,
    "grounding_metadata": {
      "grounding_support": "enabled",
      "search_queries": ["query1", "query2"],
      "maps_queries": []
    }
  }
}
```

### Informations sur les Providers

#### GET `/llm/providers`

Retourne la liste des providers disponibles.

**R√©ponse :**
```json
{
  "google": {
    "name": "Google Gemini",
    "models": ["gemini-2.5-flash-lite", "gemini-2.5-flash", "gemini-3-flash-preview"]
  },
  "openai": {
    "name": "OpenAI",
    "models": ["gpt-4", "gpt-3.5-turbo"]
  }
}
```

#### GET `/llm/models`

Retourne les mod√®les disponibles pour un provider sp√©cifique.

**Param√®tres :**
- `provider` (query, optionnel) : Provider sp√©cifique

**R√©ponse :**
```json
{
  "google": ["gemini-2.5-flash-lite", "gemini-2.5-flash", "gemini-3-flash-preview"],
  "openai": ["gpt-4", "gpt-3.5-turbo"]
}
```

### Health Checks

#### GET `/health`

Health check basique.

#### GET `/health/detailed`

Health check d√©taill√© incluant le statut des providers LLM.

## üîß Configuration

### Module Shared

Le Core Service utilise le package `shared` pour :
- **CORS** : Configuration CORS s√©curis√©e et adapt√©e √† l'environnement
- **Health checks** : Endpoints de sant√© standardis√©s avec v√©rification des d√©pendances
- **Logging** : Logs structur√©s (JSON en production, pretty en d√©veloppement)
- **Auth service-to-service** : Authentification JWT s√©curis√©e pour la communication inter-services
- **Configuration** : Settings type-safe avec Pydantic

Voir [shared/README.md](../shared/README.md) pour plus de d√©tails.

### Variables d'Environnement

| Variable | Description | Obligatoire |
|----------|-------------|-------------|
| `GOOGLE_API_KEY` | Cl√© API Google Gemini | Oui |
| `OPENAI_API_KEY` | Cl√© API OpenAI | Non |
| `SERVICE_SECRET` | Secret pour authentification service-to-service | Oui |

### Configuration Google Gemini

1. Obtenir une cl√© API sur [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Configurer `GOOGLE_API_KEY` dans l'environnement
3. Le service utilise automatiquement la nouvelle API `google.genai`

## ü§ñ Providers Support√©s

### Google Gemini

**Mod√®les disponibles :**
- `gemini-2.5-flash-lite` (par d√©faut) - Rapide et √©conomique
- `gemini-2.5-flash` - √âquilibr√© vitesse/qualit√©
- `gemini-3-flash-preview` - Qualit√© maximale

**Fonctionnalit√©s sp√©ciales :**
- **Google Search grounding** : `use_search=true` pour acc√©der aux donn√©es web en temps r√©el
- **Google Maps grounding** : `use_maps=true` pour les informations g√©ographiques

**Exemple avec Google Search :**
```bash
curl -X POST http://localhost:8001/llm/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Recherche les derni√®res informations sur Decathlon Lyon",
    "provider": "google",
    "model": "gemini-2.5-flash-lite",
    "use_search": true,
    "temperature": 0.3
  }'
```

### OpenAI

**Mod√®les disponibles :**
- `gpt-4` - Mod√®le le plus avanc√©
- `gpt-3.5-turbo` - Rapide et √©conomique

**Note :** OpenAI ne supporte pas le grounding (use_search/use_maps).

## üìä Exemples d'Utilisation

### 1. G√©n√©ration Simple

```bash
curl -X POST http://localhost:8001/llm/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Explique-moi ce qu'est l'intelligence artificielle",
    "provider": "google",
    "model": "gemini-2.5-flash-lite"
  }'
```

### 2. Avec Google Search Grounding

```bash
curl -X POST http://localhost:8001/llm/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Trouve les derni√®res informations sur les d√©veloppements en IA en 2024",
    "provider": "google",
    "model": "gemini-2.5-flash-lite",
    "use_search": true,
    "temperature": 0.3
  }'
```

### 3. Avec Google Maps Grounding

```bash
curl -X POST http://localhost:8001/llm/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Trouve des restaurants pr√®s de la Tour Eiffel √† Paris",
    "provider": "google",
    "model": "gemini-2.5-flash-lite",
    "use_maps": true,
    "temperature": 0.3
  }'
```

### 4. Avec OpenAI

```bash
curl -X POST http://localhost:8001/llm/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Analyse les avantages de l'IA dans l'√©ducation",
    "provider": "openai",
    "model": "gpt-4",
    "temperature": 0.7
  }'
```

## üîç Health Checks

### V√©rifier le statut des providers

```bash
curl http://localhost:8001/llm/health
```

### Health check d√©taill√©

```bash
curl http://localhost:8001/health/detailed
```

## üõ†Ô∏è D√©veloppement

### Structure des Providers

```mermaid
classDiagram
    class LLMProviderBase {
        <<interface>>
        +generate(request: LLMRequest) LLMResponse
        +health_check() bool
        +get_available_models() list[str]
    }
    
    class GoogleProvider {
        +client: genai.Client
        +models: dict
        +generate(request: LLMRequest) LLMResponse
        +health_check() bool
        +get_available_models() list[str]
    }
    
    class OpenAIProvider {
        +client: openai.AsyncOpenAI
        +models: dict
        +generate(request: LLMRequest) LLMResponse
        +health_check() bool
        +get_available_models() list[str]
    }
    
    LLMProviderBase <|-- GoogleProvider
    LLMProviderBase <|-- OpenAIProvider
```

### Ajout d'un nouveau provider

1. Cr√©er un nouveau fichier dans `providers/`
2. H√©riter de `LLMProviderBase`
3. Impl√©menter les m√©thodes requises
4. Enregistrer dans `llm_factory.py`

## üìà Monitoring

### Logs

```bash
# Logs du Core Service
docker logs -f novialoom-core
```

### M√©triques

Le service expose des m√©triques via les r√©ponses :
- Usage des tokens
- Temps de r√©ponse
- Statut des providers
- Grounding metadata (Google uniquement)

## üö® Gestion d'Erreurs

### Erreurs communes

- **401 UNAUTHENTICATED** : Cl√© API invalide
- **422 Validation Error** : Param√®tres invalides
- **500 Internal Server Error** : Erreur du provider LLM

### Fallback

En cas d'erreur avec un provider, le service peut basculer automatiquement vers un provider de secours (si configur√©).

---

**Core Service** - Infrastructure LLM robuste avec support Google Search et Google Maps grounding.
